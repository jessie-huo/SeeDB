import math
import os
import psycopg2
import numpy as np
import copy


# params
n_phase = 8
delta = 0.02
k = 5
A = ['age', 'workclass', 'education', 'occupation', 'race', 'native_country']
M = ['age', 'capital_loss', 'capital_gain']
F = ['avg', 'sum', 'max']
views = {}
for a in A:
    for m in M:
        for f in F:
            views[len(views)] = [a, m, f]
accept_views = []


def create_tables(conn, curs):
    csv_filepath = os.getcwd() + '/CensusData/'

    # cleanup
    curs.execute('drop view if exists tar, ref;')
    for i in range(1, n_phase + 1):
        curs.execute('drop view if exists tar{}, ref{};'.format(i, i))
    curs.execute('DROP TABLE IF EXISTS all_data, target, reference')
    for i in range(1, n_phase + 1):
        curs.execute('DROP TABLE IF EXISTS t{}, t{}_tar, t{}_ref'.format(i, i, i))
    
    # create table all_data
    curs.execute('create table all_data (age real, workclass text, fnlwgt real, education text, education_num real, marital_status text, occupation text, relationship text, race text, sex text, capital_gain real, capital_loss real, hours_per_week real, native_country text, economic_indicator text);')
    f = open(csv_filepath + 'adult.all')
    curs.copy_from(f, 'all_data', sep=',')
    f.close()
    # create table target, reference
    curs.execute("create table target as select * from all_data where marital_status in (' Married-AF-spouse', ' Married-civ-spouse', ' Married-spouse-absent', ' Separated');")
    curs.execute("create table reference as select * from all_data where marital_status in (' Widowed', ' Never-married', ' Divorced');")
    # create table t1 ~ t8, t1_tar ~ t8_tar, t1_ref ~ t8_ref
    for i in range(1, n_phase + 1):
        curs.execute('create table t{} (age real, workclass text, fnlwgt real, education text, education_num real, marital_status text, occupation text, relationship text, race text, sex text, capital_gain real, capital_loss real, hours_per_week real, native_country text, economic_indicator text);'.format(i))
        f = open(csv_filepath + 'phase_' + str(i))
        curs.copy_from(f, 't' + str(i), sep=',')
        f.close()
        curs.execute("create table t{}_tar as select * from t{} where marital_status in (' Married-AF-spouse', ' Married-civ-spouse', ' Married-spouse-absent', ' Separated');".format(i, i))
        curs.execute("create table t{}_ref as select * from t{} where marital_status in (' Widowed', ' Never-married', ' Divorced');".format(i, i))
    
    conn.commit()

def create_db_session():
    conn = psycopg2.connect('dbname=jhuo user=jhuo host=cs645db.cs.umass.edu port=7645')
    curs = conn.cursor()
    return conn, curs

# table_name is the table to apply the query, view_name is the name of the view which is generated by the query
def share_based_optimization(conn, curs, table_name, view_name):
    # generate clauses used in query
    clause1 = ','.join(A)
    clause3 = '(' + '),('.join(A) + ')'
    clause2 = []
    for i, [_, m, f] in views.items():
        clause2.append('{}({}) as view{}'.format(f, m, i))
    clause2 = ','.join(clause2)

    # create view view_name
    curs.execute('create or replace view {} as select {}, {} from {} group by grouping sets ({});'.format(view_name, clause1, clause2, table_name, clause3))
    conn.commit()
    #curs.execute('select {}, {} from {} group by grouping sets ({});'.format(clause1, clause2, table_name, clause3))
    #col = [d[0] for d in curs.description]
    #return curs.fetchall(), col

def calculate_epsilon_m(m, N = n_phase, delta = delta):
    return ((1-(m-1)/N)*((2*math.log2(math.log2(m)))+(math.log2(math.pi**2/3*delta)))/(2*m))**0.5

# views_scores = {view_1:SOME_VALUE(KL-divergence), view_2:SOME_VALUE, view_3:SOME_VALUE}
# m = current phase
# run once at end of each phase
# implemented based of ref[37] pseudocode
# assume views, views_scores only contains valid views (not including removed ones)
def CI_pruning(views, views_scores, m):
    global k
    epsilon_m = calculate_epsilon_m(m)
    stats = {}

    # loop through each view to calculate mean, lowerbound, upperbound
    for view, val in views_scores.items():
        if view not in stats:
            stats[view] = {}
        stats[view]["mean"] = np.mean(val)
        stats[view]["upper"] = stats[view]["mean"] + epsilon_m
        stats[view]["lower"] = stats[view]["mean"] - epsilon_m

    # sort by upperbound, get top k views
    views_sort_by_upper = sorted(stats, key=lambda x: (stats[x]['upper']), reverse=True) # return views name
    top_k_views = views_sort_by_upper[:k]

    # find min(lowerbound) of top_k_views
    min_lower = stats[top_k_views[0]]["lower"]
    for view in top_k_views:
        min_lower = min(min_lower, stats[view]["lower"])

    for view, stat in stats.items():
        if view not in top_k_views:
            if stat["upper"] < min_lower:
                del views[view]
                del views_scores[view]
    return views, views_scores

# run once at end of each phase
# implemented based of ref[37] pseudocode
# assume views, views_scores only contains valid views (not including removed ones)
# top-k-views  = accept_views + remaining_ones_in_views (sort by mean)
def MAB_pruning(views, views_scores):
    # loop through each view to calculate mean
    stats = {}
    for view, val in views_scores.items():
        if view not in stats:
            stats[view] = {}
        stats[view]["mean"] = np.mean(val)

    # sort by mean
    views_sort_by_mean = sorted(stats, key=lambda x: (stats[x]['mean']), reverse=True)  # return views name
    print(len(stats))
    print(len(views_sort_by_mean))
    delta_1 = stats[views_sort_by_mean[0]]["mean"] - stats[views_sort_by_mean[k]]["mean"]
    delta_n = stats[views_sort_by_mean[k-1]]["mean"] - stats[views_sort_by_mean[-1]]["mean"]
    if delta_1 > delta_n:
        accept_views.append(views_sort_by_mean[0])
        del views[views_sort_by_mean[0]]
        del views_scores[views_sort_by_mean[0]]
    else:
        del views[views_sort_by_mean[-1]]
        del views_scores[views_sort_by_mean[-1]]
    return views, views_scores

# https://towardsdatascience.com/kl-divergence-python-example-b87069e4b810
# tar and ref are numpy 1d arrays
def KL_divergence(tar, ref):
    if np.sum(tar) != 0 and np.sum(ref) != 0:
        tar = tar / np.sum(tar)
        ref = ref / np.sum(ref)
        return np.sum([p * np.log(p / q) for p, q in zip(tar, ref) if p != 0 and q != 0])
    else:
        return 0

def plot(view_id, curs):
    a, m, f = views[id]
    # get data
    curs.execute('SELECT {}, {}({}) FROM target GROUP BY {};'.format(a, f, m, a))
    target = dict(curs.fetchall())
    curs.execute('SELECT {}, {}({}) FROM reference GROUP BY {};'.format(a, f, m, a))
    reference = dict(curs.fetchall())
    # delete keys that only exist in target or reference
    common_keys = set(target.keys()).intersection(set(reference.keys()))
    for k in set(target.keys()) - common_keys:
        del target[k]
    for k in set(reference.keys()) - common_keys:
        del reference[k]
    # write plotting data to file for later use
    file = open("plot_data.txt", "a")
    for s in [a, m, f, target, reference]:
        file.write(str(s) + '\n')
    file.close()


if __name__ == '__main__':
    conn, curs = create_db_session()
    create_tables(conn, curs)

    # share based optim
    share_based_optimization(conn, curs, 'target', 'tar')
    share_based_optimization(conn, curs, 'reference', 'ref')
    
    # get distance between tar and ref distribution for each view
    view_dists = {}
    for id, [a, m, f] in views.items():
        curs.execute('select tar.view{}, ref.view{} from tar, ref where tar.{} = ref.{} and ref.{} is not null;'.format(id, id, a, a, a))
        joined_data = curs.fetchall()
        tar_val, ref_val = np.zeros(len(joined_data)), np.zeros(len(joined_data))
        for i, (tar, ref) in enumerate(joined_data):
            tar_val[i] = tar
            ref_val[i] = ref
        dist = KL_divergence(tar_val, ref_val)
        view_dists[id] = dist

    # rank the views by distance
    ranked_views = sorted(view_dists.items(), key = lambda x: x[1], reverse=True)
    print('The views ordered by KL divergence distance score: ', ranked_views)
    
    # plot top 3 views
    #for id, _ in ranked_views[:3]:
    #    plot(id, curs)
    
    # Pruning
    remaining_views = copy.deepcopy(views)
    remaining_dists = {i:[] for i in range(len(views))}

    for i in range(1, n_phase + 1):
        print('phase {} ==============='.format(i))
        # Share
        share_based_optimization(conn, curs, 't{}_tar'.format(i), 'tar{}'.format(i))
        share_based_optimization(conn, curs, 't{}_ref'.format(i), 'ref{}'.format(i))
        for id, [a, m, f] in remaining_views.items():
            curs.execute('select tar{}.view{}, ref{}.view{} from tar{}, ref{} where tar{}.{} = ref{}.{} and ref{}.{} is not null;'.format(i, id, i, id, i, i, i, a, i, a, i, a))
            joined_data = curs.fetchall()
            tar_val, ref_val = np.zeros(len(joined_data)), np.zeros(len(joined_data))
            for j, (tar, ref) in enumerate(joined_data):
                tar_val[j] = tar
                ref_val[j] = ref
            dist = KL_divergence(tar_val, ref_val)
            remaining_dists[id].append(dist)
        
        # CI prune
        if i > 1:
            remaining_views, remaining_dists = CI_pruning(remaining_views, remaining_dists, i)

        # MAB prune
        print(len(remaining_dists))
        if len(remaining_dists) > k:
            remaining_views, remaining_dists = MAB_pruning(remaining_views, remaining_dists)

    # plot top K views (those in accept_views and if not enough, find in remaining views and sort by mean)
    if len(accept_views) >= k:
        for id in accept_views[:k]:
            plot(id, curs)
    else:
        for id in accept_views:
            plot(id, curs)
        ranked_views = sorted(remaining_dists.items(), key = lambda x: np.mean(x[1]), reverse=True)
        for id, _ in ranked_views[:k - len(accept_views)]:
            plot(id, curs)